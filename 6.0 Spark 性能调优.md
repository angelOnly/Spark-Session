## 性能调优

### 1. 增大内存

**分配哪些资源？**

executor，cpu executor，memory per executor，driver memory

**在哪里分配资源？**

在生产环境中，提交spark作业时，用 spark-submit shell 脚本时，里面调整对应的参数。

````shell
/usr/local/spark/bin/spark-submit\
--class cn.spark.sparktest.core.WordCountCluster\
--num-executor 3\ # 配置executor的数量
--driver-memory 100m\ #配置driver memory(影响不大)
--executor-memory 100m\ #配置memory per executor
--executor-cores 3\ #配置每个executor的cpu core数量
/usr/local/SparkTest-0.0.1-SNAPSHOT-jar-with-dependencies.jar
````

调节到多大，算是最大呢？

1. spark standalone：根据实际情况分配spark资源分配。
2. Yarn：资源队列，资源调度，看spark作业提交的到的资源队列大概有多少资源。

### 2. 提高并行度

**增加executor**

executor 越多，并行执行的task就越多，并行能力越高。

**增加每个executor 的 cpu core**

也相当于增大并行度

**增大每个executor的内存量**

1. 如果需要对RDD进行cache，那么更多的内存，就可以缓存更多数据，将更少的资源写入磁盘IO。
2. 对于shuffle操作，reduce端，会需要内存存放拉取的数据并进行聚合，如果内存不够，也会写入磁盘，如果给executor分配足够内存，则更少数据写入磁盘IO，甚至没有数据需要写入。
3. 对于task的执行，可能会创建很多对象，如果内存小，可能会导致频繁GC，速度变慢。

### 3. Broadcast广播变量

[Spark性能调优：广播大变量broadcast](https://blog.csdn.net/leen0304/article/details/78720838/)

### 4. 算子调优

1. mapPartitions提升map性能

   - 解决
     - 对partition进行压缩，数据量变小，则partition完全可以对应的变少

2. filter过后使用coalesce减少分区数量

   1. **原因**
      - filter后RDD中每个partition的数据量不一样，但是后面进行处理时，还是要跟partitions数量一样的task，有点浪费task资源。

   ​         每个partition数据量不同，会导致后面每个task处理时，没有task要处理的数据量不同，这时候就容易发生数据倾斜。

   2. 解决
      - 压缩partition，尽量让每个partition数据量差不多，这样task分配的partition数据量也就差不多。后面分配的partition数据量也就差不多，不会造成有task运行速度特曼，有的task速度特快，避免数据倾斜。
      - **coalesce算子：** 在filter操作之后，针对每个partition数据量各不相同的情况，来压缩partition的数量，减少partition的数量且让每个partition数据量尽量均匀。



````java
public static JavaPairRDD<String, Row> getSessionid2ActionRDD(JavaRDD<Row> actionRDD) {
    return actionRDD.mapPartitionsToPair(iterator -> {
        List<Tuple2<String, Row>> list = new ArrayList<Tuple2<String,Row>>();
        while (iterator.hasNext()) {
            Row row = iterator.next();
            list.add(new Tuple2<String, Row>(row.getString(2), row));
        }
        return list;
    });
}

final Broadcast<Map<String, Map<String, List<Integer>>>> dateHourExtractMapBroadCast = sc.broadcast(dateHourExtractMap);

Map<String, Map<String, List<Integer>>> dateHourExtractMapBC = dateHourExtractMapBroadCast.getValue();
````



